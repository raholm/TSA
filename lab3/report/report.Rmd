---
title: "732A62 Lab 3"
author: "Emil K Svensson & Rasmus Holm"
date: "`r Sys.Date()`"
output:
    pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(astsa)
library(TSA)
library(forecast)
library(fGarch)
```

# Assignment 1

## 1)

```{r}


plot(chicken)
```

It looks like a linear, potentially quadratic, trend.

## 2)

```{r}
lm_data <- data.frame(chicken=chicken, time=1:length(chicken))
lm_fit <- lm(chicken ~ time, lm_data)
z <- resid(lm_fit)
plot(z, type="l", ylab="resid", xlab="Time")
```

The residuals do not look stationary. The data is definitely correlated.

## 3)

```{r}
denom <- sqrt(length(z)) *
    exp(complex(imaginary=2 * pi * 0:(length(z) - 1) / length(z)))
density <- fft(z) / denom
periodigram <- abs(density)^2

upper <- 2 * mean(periodigram) / qchisq(0.025, 2)
lower <- 2 * mean(periodigram) / qchisq(0.975, 2)

plot(0:(length(chicken) - 1) / length(chicken), periodigram, type="o",
     xlab="frequency", ylab="spectrum")
abline(h=lower, col="red", lwd=2)
```

We can see that low and high frequencies are the dominant frequencies. We decided to use the mean as the baseline which sets the lower limit close to zero. This results in that most non-zero frequencies are significant.

## 4)

```{r}
freq_density <- density
freq_density[periodigram < lower] <- 0

n <- length(z)
ts <- 1:(n + 36)

xs <- rep(0, n + 36)

for (t in ts) {
    xs[t] <- sum(freq_density * exp(complex(imaginary=2 * pi * (0:(n - 1)) / n * t))) / sqrt(n)
}

filtered_data <- predict(lm_fit, data.frame(time=1:length(xs))) + Re(xs)
```

```{r, fig.height=8, echo=FALSE}
old <- par(mfrow=c(2, 1))
plot(z, type="l", main="Zt")
lines(Re(xs), col="red")
plot(1:length(chicken), chicken, type="l",
     xlim=c(0, length(xs)),
     ylim=c(60, max(filtered_data)),
     main="Filtered Data")
lines(filtered_data, col="red")
par(old)
```

The forecast do look reasonable since it follows the general trend well.

## 5)

```{r}
k <- kernel("modified.daniell", c(2,2))
md_dan <- mvspec(z, kernel=k, log="no")
Lh <- md_dan$Lh

lower1 <- 2 * Lh * md_dan$spec / qchisq(0.975,2*Lh)
upper1 <- 2 * Lh * md_dan$spec / qchisq(0.025,2*Lh)

# Comparing frequencies

freq_4 <- 0:179/180

freq_4[periodigram > lower]
md_dan$freq[md_dan$freq < 0.1]
```

We can see that similar frequencies were found by smoothing the spectrum so the smoothing does seem to help.

```{r, echo=FALSE}
plot(x = md_dan$freq, y = md_dan$spec, type = "o")
lines(x = md_dan$freq, y = lower1 , col = "blue")
lines(x = md_dan$freq, y = upper1 , col = "blue")
```

## 6)

```{r}
fit_plot <- function(model, data) {
    nahead <- 36
    pred <- predict(model, n.ahead=nahead, se.fit=TRUE)
    upper_band <- pred$pred + 1.96 * pred$se
    lower_band <- pred$pred - 1.96 * pred$se

    n <- length(data)

    plot(c(data, pred$pred), type="l",
         ylim=c(min(data), max(upper_band)), ylab="Value", xlab="Time")
    lines(n + 1:nahead, upper_band, lty=2, col="red")
    lines(n + 1:nahead, lower_band, lty=2, col="red")
}
```

```{r}
fit <- arima(chicken, order=c(2, 1, 0), seasonal=list(order=c(0, 0, 1), period=12))
residuals <- residuals(fit)
```

```{r, echo=FALSE, fig.height=8}
old <- par(mfrow=c(2, 1))
plot(residuals, type="l", main="Residuals")
acf(residuals)
par(old)
```

The model seem to fit the data decent with no correlation. However, the variance seem to decrease with time so it may not be completely stationary.

```{r, echo=FALSE}
fit_plot(fit, chicken)
```

The forecast do not look very good because it does not follow the general trend. We would rather trust the forecast from 1.4.

## 7)

```{r}
fit <- arima(chicken, order=c(3, 0, 0), seasonal=list(order=c(0, 0, 1), period=12))
residuals <- residuals(fit)
```

```{r, echo=FALSE, fig.height=8}
old <- par(mfrow=c(2, 1))
plot(residuals, type="l", main="Residuals")
acf(residuals)
par(old)
```

The residuals looks similar to those from the other fit. Uncorrelated but not stationary because of changing variance.

```{r}
mvspec(residuals, log="no")
```

We can see that the spectrum is non-zero for a lot of frequencies and not just low ones. This indicates that the residuals are not stationary.

\newpage

# Assignment 2

## 1)

```{r}

ld_oil <-diff(log(oil))

z <-ld_oil[1:(52*9 + 33)]

old <- par(mfrow = c(1,2))
acf(z)
pacf(z)
par(old)

suggested_model <- Arima(z, order = c(3,0,0))

summary(suggested_model)

suggested_model$coef +  1.96 * sqrt(diag(suggested_model$var.coef))
suggested_model$coef -  1.96 * sqrt(diag(suggested_model$var.coef))


r <- resid(suggested_model)
```
The ACF is dying down
All coefficients of the AR3 model is significant so we move forward with it.
## 2)

```{r}
plot(r)
old <- par(mfrow = c(1,2))
acf(r^2)
pacf(r^2)
par(old)


fit1<- garchFit(~ arma(3,0) + garch(1,1) , data = ld_oil, trace = FALSE)
fit1

```

The time series of the residuals seem to have an increasing variance in the end of the residuals.

The ACF of the squared residuals trails of and in the PACF they cuts of after 2 lags. Indicating a GARCH(p,q)
 An p = 2, q = 0 maybe?



## 3)
```{r}
fit1<- garchFit(~ arma(3,0) + garch(1,0) , data = ld_oil, trace = FALSE)
fit1
```

After starting with an ARMA-GARCH(3,0)-(3,0) we itteratively decrease the order of the p' since terms of the GARCH part is unsignificant. We end up with a ARMA-GARCH(3,0)-(1,0) where all parameters are significant.


```{r}


helper <- function(fit){
  data <- fit@residuals
# acf(scale(data)) # ACF
# acf(data^2)# ACF^2
# qqnorm(data) # QQ-plot
# qqline(data)
print(jarque.bera.test(data)) #Jarque bera-test
print(Box.test(data, lag = 1, type = c( "Ljung-Box"))) # Ljung Box -test
print(fit@fit$matcoef) # Significance.
print(fit@fit$ics) # AIC and Bic
}


plot(fit1, which = c(9,10,11,13))
helper(fit1)



```

The GARCH(p,q) part of the model looks as follows.

$$ \sigma_t^2 = 0.0016814 + 0.1863076r^2_{t-1} $$

 ACF seems to be stationary and the squared residuals dies down after around 10 lags. The QQ plot as a big tail in the left hand side of the graf but hat is the outliers of the end of the time series. Otherwise it looks like it is normaly distributed.

Jarque-Bera test returns a p-value of 0 and therefor we reject the null-hypothesis that the residuals are normaly distributed. This test is argued to have a tendency to give false positives with small observations, Matlab for instance approximate the p-value with an MCMC when the number of observations are below 2000.

The Box-Ljung is non-significant so we conclude the null hypothesis and say that the observations are stationary.

The AIC and BIC are measures only intressting with another model so its hard to say anything about them.

## 4)

```{r}
plot(z, type ="l")
lines(volatility(fit1), col = "red")
```

The volatility seems to match the patterns of the observed data very well. Even matching the outliers resonably good.

## 5)

```{r}
omega.fit1 <- 0.0016814
alpha.fit1 <- 0.1863076
sims <- garch.sim(alpha = c(omega.fit1, alpha.fit1) , n = 500)

plot(z, type ="l")
lines(sims,  col = "red")
```

The red simulated data seems to be quite similar to the observed data which is a good sign that we choosen the right model.


## 6)

```{r}
fit2<- garchFit(~ arma(1,0) + garch(1,0) , data = ld_oil, trace = FALSE)
pred.fit1 <- predict(fit2, n.ahead = 45)

lower.fit <- pred.fit1$meanForecast - 1.96*pred.fit1$standardDeviation
upper.fit <- pred.fit1$meanForecast + 1.96*pred.fit1$standardDeviation


x_lim_band<- (length(z)+1) : (length(z)+length(lower.fit))

plot(c(z,pred.fit1$meanForecast), type = "l", col = "black", lwd =1.25, ylab ="ld_oil", las = 1)
lines(x = x_lim_band[1]:length(ld_oil),
      y = ld_oil[x_lim_band[1]:length(ld_oil)],
      col = "blue")
lines(x = x_lim_band, lower.fit, col = "red")
lines(x = x_lim_band,upper.fit, col = "red")
```


Since we have some unexplained error with a ARMA-GARCH(3,0)(1,0) we use a ARMA-GARCH(1,0)(1,0) since the only mention of this error is in on thread in Stackoverflow where the solution was contacting the maintainer of the fGarch-package. The prediction bands contain the observed balues (represented by a blue line). The mean prediction seems to be around 0.
