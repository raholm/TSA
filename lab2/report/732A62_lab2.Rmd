---
title: "732A62 Lab 2"
author: "Emil K Svensson & Rasmus Holm"
date: "`r Sys.Date()`"
output:
    pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(astsa)
library(kernlab)
library(TSA)
library(forecast)
```

# Assignment 1

# a)

```{r}
set.seed(12345)
AR3 <- arima.sim(1000, model = list(order = c(3,0,0),
                                    ar = c(0.8, -0.2, 0.1)))

## The theoretical
AR3.pacf <- pacf(AR3, plot=F)
AR3.data <- ts.intersect(xt = AR3, x1 = lag(AR3, 1), x2 = lag(AR3, 2), x3 = lag(AR3, 3))

AR.lm <- resid(lm(xt ~ x1 + x2, data = AR3.data))
AR.lm.lag3 <- resid(lm(x3 ~ x1 + x2 , data = AR3.data))

AR3.pacf[3]
cat(paste("The theoretical value:",round(cor(AR.lm, AR.lm.lag3), digits = 3)))
```

As seen above the theoretical and the output from the pacf-function are very similar.

# b)

```{r}
set.seed(12345)
AR2 <- arima.sim(100, model = list(order = c(2,0,0),
                                   ar = c(0.8, 0.1)))

ar2.yw <- ar(AR2, order.max = 2, method = "yw", aic = FALSE)
ar2.ols <- ar(AR2, order.max = 2, method = "ols", aic = FALSE)
ar2.mle <- arima(AR2, order = c(2,0,0), method = "ML")

ar2.yw$ar
ar2.ols$ar
ar2.mle$coef
```

The Yule Walker estimate seems to have the parameters closes to the true parameters given in the assignment.

```{r}
ar2.mle
```

Yes, the theoretical value for $$\phi_2$$ is inside the confidence-intervall for the ML estimate which can seen from the s.e times 1.96 which obviously will cover the true coefficients.

# c)

```{r}
set.seed(12345)
ma.coef <- c(0.3, rep(0, 10), 0.6)
ts4 <- arima.sim(n=200, model=list(order=c(0, 0, 12), ma = ma.coef))

theoretical.acf <- ARMAacf(ma=c(ma.coef, 0.3 * 0.6))
theoretical.pacf <- ARMAacf(ma=c(ma.coef, 0.3 * 0.6), pacf=TRUE)
```

```{r, fig.height=10, echo=FALSE}
old <- par(mfrow=c(4, 1))
plot(theoretical.acf, type="h", main="Theoretical ACF")
abline(h=0)
empirical.acf <- acf(ts4, main="Empirical ACF")
plot(theoretical.pacf, type="h", main="Theoretical PACF")
abline(h=0)
empirical.pacf <- pacf(ts4, main="Empirical PACF")
par(old)
```

The patterns seem to be somewhat similar. In the theoretical ACF we can see a large spike at lags  1 and 13 and in the sample ACF we have large spikes at lags 1 and 12 instead. The difference between the two being that the sample ACF has some correlation along the lags although under the confidence interval.

For the PACF we can see a similar observation that there are spikes at lags 1 and 12 for both the theoretical and sample PACF.

# d)

```{r, results="hide"}
set.seed(12345)
ma.coef <- c(0.3, rep(0, 10), 0.6)
ts5 <- arima.sim(n=200, model=list(order=c(0, 0, 12), ma = ma.coef))

ts5.fit <- arima(ts5, order=c(0, 0, 1), seasonal=list(order=c(0, 0, 1), period=12))
ts5.pred <- predict(ts5.fit, n.ahead=30, se.fit=TRUE)

gausspr.data <- data.frame(y=ts5, x=1:200)
gausspr.fit <- gausspr(y ~ x, gausspr.data)
gausspr.pred <- predict(gausspr.fit, data.frame(x=201:230))
```

```{r, echo=FALSE, fig.height=8}
old <- par(mfrow=c(2, 1))
plot(ts(c(ts5, ts5.pred$pred)), ylim=c(-4, 4), ylab="value")
lines(200 + 1:length(ts5.pred$pred), ts5.pred$pred + 1.96 * ts5.pred$se, lty=2, col="red")
lines(200 + 1:length(ts5.pred$pred), ts5.pred$pred - 1.96 * ts5.pred$se, lty=2, col="red")
plot(ts5, xlim=c(0, 230), ylab="value")
lines(c(fitted(gausspr.fit), gausspr.pred), , col="red")
par(old)
```

In the first plot we can see the MA models predictions seem reasonable but after a while the predictions just tails of in to a mean function at y = 0.

For the gaussian process there is an initial jump in the predictions and afterwards continues with a smoothed pattern similar to the fitted line in the observed data.

# e)

```{r}
set.seed(12345)
ts6 <- arima.sim(model=list(ma=c(0.5), ar=c(0.7)), n=50)

train <- ts(ts6[1:40])
test <- ts(ts6[41:50])

ts6.fit <- arima(train, order=c(1, 0, 1), include.mean = F)
ts6.pred <- predict(ts6.fit, n.ahead=10)
```

```{r, echo=FALSE, fig.height=8}
old <- par(mfrow=c(2, 1))
plot(ts(c(train, test)), ylim=c(-4, 7), type="l", ylab="value")
lines(40 + 1:length(test), ts6.pred$pred, col="blue")
lines(40 + 1:length(test), ts6.pred$pred + 1.96 * ts6.pred$se, lty=2, col="red")
lines(40 + 1:length(test), ts6.pred$pred - 1.96 * ts6.pred$se, lty=2, col="red")

plot(40 + 1:length(test), test, ylim=c(-4, 7), xlim=c(40, 50), type="p", ylab="value", xlab="Time")
points(40 + 1:length(test), ts6.pred$pred, col="blue")
lines(40 + 1:length(test), ts6.pred$pred + 1.96 * ts6.pred$se, lty=2, col="red")
lines(40 + 1:length(test), ts6.pred$pred - 1.96 * ts6.pred$se, lty=2, col="red")
par(old)
```

The first of the 10 observations withheld from the fitted model is the only observation that is not in the prediction interval. Since it is a 95 % prediction interval we say that we expect that 5 of 100 observations will be outside the interval so it is not unreasonable that 1 of 10 is outside the interval.

\newpage

# Assignment 2

```{r}
assignment2 <- function(data){
    old <- par(mfrow = c(2, 2))
    acf(data, lag.max = 40, main="Data ACF")
    pacf(data, lag.max = 40, main="Data PACF")
    acf(diff(data, lag = 1), lag.max = 40, main="Difference 1 Data ACF")
    pacf(diff(data, lag = 1), lag.max = 40, main="Difference 1 Data PACF")
    par(old)
}
```

## Chicken

```{r, echo=FALSE, fig.height=10}
assignment2(chicken)
```

### Data ACF
The ACF on the original data suggests an AR or ARMA model since the ACF tails off.

### Data PACF
The PACF on the original data cuts off after lag 1 suggesting an AR(1) model.

### Difference 1 Data ACF
After having performed difference of order 1 we can clearly see that there is a seasonal trend in the data. The ACF suggests a seasonality of 12 that tails off for a while then goes up again. This may indicate an AR model.

### Difference 1 Data PACF
The PACF shows that the seasonality cuts off after lag 12 which is 1 * 12 indicating an AR(1) model.

### Final Verdict
ARIMA(1, 0, 0) x $(1, 1, 0)_{12}$


\newpage

## so2

```{r, echo=FALSE, fig.height=10}
assignment2(so2)
```

### Data ACF
The ACF tails off suggesting either an AR or ARMA model.

### Data PACF
The PACF tails off as well suggesting an ARMA model.

### Difference 1 Data ACF
The ACF after difference cuts off after lag 1 suggesting a MA(1) model.

### Difference 1 Data PACF
The PACF after difference tails off further suggesting a MA(1) model.

### Final Verdict
ARIMA(0, 1, 1)

\newpage

## EQcount

```{r, echo=FALSE, fig.height=10}
assignment2(EQcount)
```

### Data ACF
The ACF tails off suggesting an AR or ARMA model.

### Data PACF
The PACF cuts off after lag 1 suggesting AR(1) model.

### Difference 1 Data ACF
The ACF after difference cuts off after lag 1 suggesting a MA(1) model.

### Difference 1 Data PACF
The PACF after difference tails off further suggesting a MA model.

### Final Verdict
Either a ARMA(1, 0, 0) or ARMA(0, 1, 1)

\newpage

## HCT

```{r, echo=FALSE, fig.height=10}
assignment2(HCT)
```

### Data ACF
The ACF tails off suggesting either an AR or ARMA model.

### Data PACF
The PACF cuts off after lag 7 suggesting an AR(7) model.

### Difference 1 Data ACF
The ACF suggests seasonality that tails off after lag 7 suggesting an seasonality of 7.

### Difference 1 Data PACF
The PACF cuts off after 6 lags suggesting an AR(6) seasonality model.

### Final Verdict
ARIMA(7, 0, 0)$\times(1, 1, 0)_7$

\newpage

# Assignment 3

```{r}
plot_helper <- function(data, title) {
    old <- par(mfrow=c(4, 1))
    plot(data, main=title)
    acf(data, lag.max=40, main="")
    pacf(data, lag.max=40, main="")
    qqnorm(data, main="", las=1)
    qqline(data)
    par(old)
}

test_helper <- function(data) {
    print(Box.test(data, lag = 1, type = "Ljung-Box"))
    print(suppressWarnings(adf.test(data)))
    e <- eacf(data)
}

fit_plot <- function(model) {
    pred <- predict(model, n.ahead=20, se.fit=TRUE)
    upper_band <- pred$pred + 1.96 * pred$se
    lower_band <- pred$pred - 1.96 * pred$se

    n <- length(model$x)

    plot(c(model$x, pred$pred), type="l",
         xlim=c(n - 20, n + 20),
         ylim=c(min(lower_band), max(upper_band)), ylab="Value", xlab="Time")
    lines(n + 1:20, upper_band, lty=2, col="red")
    lines(n + 1:20, lower_band, lty=2, col="red")
}
```

## a)

```{r}
loil <- log(oil)
doil <- diff(oil)
ddoil <- diff(oil, 2)
dloil <- diff(loil)
ddloil <- diff(loil, 2)
```

\newpage

```{r, fig.height=8, echo=FALSE}
old <- par(mfrow=c(2, 1))
plot(oil, main="Oil")
plot(diff(oil), main="Difference 1 Oil")
par(old)
```

```{r, fig.height=8, echo=FALSE}
old <- par(mfrow=c(2, 1))
plot(dloil, main="Difference 1 Log Oil")
plot(ddloil, main="Difference 2 Log Oil")
par(old)
```

Clearly difference log is the data we should work with, a second difference does not do any visual change to the data that can already be considerd stationary at diff 1 with a log transformation but we keep both and keep both as tenative models.

```{r}
adf.test(oil)
adf.test(loil)
adf.test(dloil)
adf.test(ddloil)
```

The Augmented Dickey-Fuller test also indicates that we should use differencing to make the data stationary.


```{r, fig.height=10, echo=FALSE}
old <- par(mfrow=c(4, 1))
acf(dloil, lag.max=40, main="Difference 1 Log Oil ACF")
pacf(dloil, lag.max=40, main="Difference 1 Log Oil PACF")
acf(ddloil, lag.max=40, main="Difference 2 Log Oil ACF")
pacf(ddloil, lag.max=40, main="Difference 2 Log Oil PACF")
par(old)
```

Here the ACF and PACF for the first order differencing dosn't seem to have any clear defined patterns compared to the second orderd differencing where we can se that the ACF cuts of at lag 1 and trails off in the PACF suggesting a ARIMA(0,2,1).

```{r}
eacf(dloil)
eacf(ddloil)
```

The EACF dosn't seem to help aliviate the ambigous ACF/PACF for the first order diff series and suggest a wide range of models making the general pattern more like a box than a triangular shape.

For the second order diff we can see the triangular shape with a point at a AR(1) which would confirm previous statements in the ACF.


\newpage

```{r}
fit1 <- Arima(loil, order=c(1, 1, 1))
fit1
fit2 <- Arima(loil, order=c(1, 2, 2))
fit2
fit3 <- Arima(loil, order=c(0, 2, 1))
fit3
```

The best model if we evaluate the BIC criterion we choose the ARIMA(0,2,1) which looks like following $$\bigtriangledown^2x_t = (1+\theta B)w_t $$

\newpage

```{r}
fit_plot(fit3)
```

The figure above displays 20 steps ahead prediction. The intervals looks resonable and the prediction as well.

\newpage

## b)

```{r}
lunemp <- log(unemp)
dunemp <- diff(unemp)
dlunemp <- diff(lunemp, 1)
ddlunemp <- diff(lunemp, 2)
```

```{r, fig.height=8, echo=FALSE}
old <- par(mfrow=c(2, 1))
plot(unemp, main="Unemp")
plot(dunemp, main="Difference 1 Unemp")
par(old)
```

```{r, fig.height=8, echo=FALSE}
old <- par(mfrow=c(2, 1))
plot(dlunemp, main="Difference 1 Log Unemp")
plot(ddlunemp, main="Difference 1 Log Unemp")
par(old)
```

The data is clearly not stationary and to try to make it stationary we do differencing of order 1. The variance seem to increase by time which we try to negative by transforming the data on log-scale. We also used differencing of order 2 which gives a smoother result than differencing of order 1.

```{r, fig.height=10, echo=FALSE}
old <- par(mfrow=c(4, 1))
acf(dlunemp, lag.max=40, main="Difference 1 Log Unemp ACF")
pacf(dlunemp, lag.max=40, main="Difference 1 Log Unemp PACF")
acf(ddlunemp, lag.max=40, main="Difference 2 Log Unemp ACF")
pacf(ddlunemp, lag.max=40, main="Difference 2 Log Unemp PACF")
par(old)
```

### Difference 1
\textbf{Seasonality behavior:} The ACF plot suggests a seasonality trend of 12 lags that tails off both in the ACF and the PACF. This suggests an $ARMA_12$ seasonality component. The PACF spikes at 3 multiples which is indicative of AR(3).

\textbf{Non-seasonality behavior:} There is no distinct non-seasonal pattern to be seen.

Our model for this data is SARMA$(3, 1, 0)_{12}$.

### Difference 2
\textbf{Seasonality behavior:} We can see that there are large spikes at lags 9, 12, 15 and then it gets insignificant until the pattern repeats at lags 21, 24, 27. So there is definitely a seasonality pattern in the data. The PACF shows that the pattern tails off over time with spikes at two 2 multiples which indicates AR(2).

\textbf{Non-seasonality behavor:} Apart from the seasonal behavior the ACF tails off and the PACF cuts off after lag 2 indicating an AR(2) model.

```{r}
eacf(dlunemp)
eacf(ddlunemp)
```

The EACF further suggest that there is no normal ARMA model that is well suited for the data.

```{r}
fit1 <- Arima(lunemp, order=c(0, 0, 0), seasonal=c(3, 1, 0))
fit1
fit2 <- Arima(lunemp, order=c(0, 0, 0), seasonal=c(2, 2, 0))
fit2
```

The second fit has better BIC/AIC which is then our final model. It can be written formally as

\begin{equation*}
(1 + 0.6655 B + 0.337 B^2) \bigtriangledown^2 x_t = w_t.
\end{equation*}

```{r}
fit_plot(fit2)
```

The predictions look reasonable good.
